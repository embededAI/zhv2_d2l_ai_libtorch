{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "round-dinner",
   "metadata": {},
   "source": [
    "# 使用前，需要先导入需要的头文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../inc/macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../inc/load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../inc/custom_def.hpp\"\n",
    "/*import matplotlibcpp*/\n",
    "#include \"../inc/load_matplotlibcpp.hpp\"\n",
    "/*import opencv*/\n",
    "#include \"../inc/load_opencv.hpp\"\n",
    "\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>\n",
    "#include <opencv2/opencv.hpp>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-channel",
   "metadata": {},
   "source": [
    "# MLP从零实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-latvia",
   "metadata": {},
   "source": [
    "## 初始化MLP的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eight-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "/** input of mnist dataset, 28*28 pixels */\n",
    "int num_inputs = 784;\n",
    "/** output of classes, totally 10 classes */\n",
    "int num_outputs = 10;\n",
    "/** hidden layers */\n",
    "int num_hiddens = 256;\n",
    "\n",
    "torch::Tensor W1 = torch::randn({num_inputs, num_hiddens}, torch::requires_grad(true));\n",
    "torch::Tensor b1 = torch::zeros({num_hiddens}, torch::requires_grad(true));\n",
    "\n",
    "torch::Tensor W2 = torch::randn({num_hiddens, num_outputs}, torch::requires_grad(true));\n",
    "torch::Tensor b2 = torch::zeros({num_outputs}, torch::requires_grad(true));\n",
    "\n",
    "std::vector<torch::Tensor> params = {W1, b1, W2, b2};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-prisoner",
   "metadata": {},
   "source": [
    "## 定义relu和mlp函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invisible-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor relu(torch::Tensor X)\n",
    "{\n",
    "    torch::Tensor a = torch::zeros_like(X);\n",
    "    return torch::max(X, a);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "german-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor net(torch::Tensor X)\n",
    "{\n",
    "    X = X.reshape({X.size(0), num_inputs});\n",
    "    torch::Tensor H = torch::relu(torch::mm(X, W1) + b1);\n",
    "    torch::Tensor y = torch::log_softmax((torch::mm(H, W2)+b2), 1);\n",
    "    return y;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-student",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "false-prediction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch: 300 | Loss: 14.2126\n",
      "Epoch: 1 | Batch: 600 | Loss: 6.97919\n",
      "Epoch: 2 | Batch: 300 | Loss: 7.21341\n",
      "Epoch: 2 | Batch: 600 | Loss: 6.43654\n",
      "Epoch: 3 | Batch: 300 | Loss: 7.51612\n",
      "Epoch: 3 | Batch: 600 | Loss: 4.39334\n",
      "Epoch: 4 | Batch: 300 | Loss: 2.7415\n",
      "Epoch: 4 | Batch: 600 | Loss: 5.02633\n",
      "Epoch: 5 | Batch: 300 | Loss: 3.70099\n",
      "Epoch: 5 | Batch: 600 | Loss: 3.67502\n",
      "Epoch: 6 | Batch: 300 | Loss: 3.88901\n",
      "Epoch: 6 | Batch: 600 | Loss: 3.06439\n",
      "Epoch: 7 | Batch: 300 | Loss: 3.32941\n",
      "Epoch: 7 | Batch: 600 | Loss: 3.55017\n",
      "Epoch: 8 | Batch: 300 | Loss: 4.19023\n",
      "Epoch: 8 | Batch: 600 | Loss: 3.20952\n",
      "Epoch: 9 | Batch: 300 | Loss: 4.04659\n",
      "Epoch: 9 | Batch: 600 | Loss: 2.65753\n",
      "Epoch: 10 | Batch: 300 | Loss: 2.64565\n",
      "Epoch: 10 | Batch: 600 | Loss: 2.78295\n",
      "Epoch: 11 | Batch: 300 | Loss: 2.11727\n",
      "Epoch: 11 | Batch: 600 | Loss: 2.66847\n",
      "Epoch: 12 | Batch: 300 | Loss: 1.87772\n",
      "Epoch: 12 | Batch: 600 | Loss: 2.54007\n",
      "Epoch: 13 | Batch: 300 | Loss: 2.27242\n",
      "Epoch: 13 | Batch: 600 | Loss: 2.86207\n",
      "Epoch: 14 | Batch: 300 | Loss: 2.54754\n",
      "Epoch: 14 | Batch: 600 | Loss: 2.6382\n",
      "Epoch: 15 | Batch: 300 | Loss: 1.99593\n",
      "Epoch: 15 | Batch: 600 | Loss: 1.75373\n",
      "Epoch: 16 | Batch: 300 | Loss: 1.7861\n",
      "Epoch: 16 | Batch: 600 | Loss: 1.34112\n",
      "Epoch: 17 | Batch: 300 | Loss: 1.46735\n",
      "Epoch: 17 | Batch: 600 | Loss: 1.3587\n",
      "Epoch: 18 | Batch: 300 | Loss: 2.05789\n",
      "Epoch: 18 | Batch: 600 | Loss: 0.888117\n",
      "Epoch: 19 | Batch: 300 | Loss: 1.84308\n",
      "Epoch: 19 | Batch: 600 | Loss: 1.55353\n",
      "Epoch: 20 | Batch: 300 | Loss: 1.05011\n",
      "Epoch: 20 | Batch: 600 | Loss: 1.46171\n",
      "Epoch: 21 | Batch: 300 | Loss: 1.74517\n",
      "Epoch: 21 | Batch: 600 | Loss: 1.32229\n",
      "Epoch: 22 | Batch: 300 | Loss: 0.799781\n",
      "Epoch: 22 | Batch: 600 | Loss: 1.78163\n",
      "Epoch: 23 | Batch: 300 | Loss: 1.86618\n",
      "Epoch: 23 | Batch: 600 | Loss: 1.17789\n",
      "Epoch: 24 | Batch: 300 | Loss: 1.31572\n",
      "Epoch: 24 | Batch: 600 | Loss: 1.97916\n",
      "Epoch: 25 | Batch: 300 | Loss: 1.07434\n",
      "Epoch: 25 | Batch: 600 | Loss: 0.933233\n",
      "Epoch: 26 | Batch: 300 | Loss: 1.16615\n",
      "Epoch: 26 | Batch: 600 | Loss: 1.2077\n",
      "Epoch: 27 | Batch: 300 | Loss: 1.59698\n",
      "Epoch: 27 | Batch: 600 | Loss: 1.00397\n",
      "Epoch: 28 | Batch: 300 | Loss: 1.28431\n",
      "Epoch: 28 | Batch: 600 | Loss: 1.53914\n",
      "Epoch: 29 | Batch: 300 | Loss: 1.38853\n",
      "Epoch: 29 | Batch: 600 | Loss: 0.788709\n",
      "Epoch: 30 | Batch: 300 | Loss: 1.2192\n",
      "Epoch: 30 | Batch: 600 | Loss: 1.24774\n",
      "\n",
      "\n",
      "Training finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "/** max number of epoch */\n",
    "constexpr int EPOCH_MAX = 30;\n",
    "/** learning rate */\n",
    "constexpr float lr = 0.01;\n",
    "\n",
    "// Instantiate loss handler\n",
    "torch::nn::CrossEntropyLoss Loss;\n",
    "\n",
    "// Instantiate an SGD optimization algorithm to update our Net's parameters.\n",
    "torch::optim::SGD optimizer(params, /*lr=*/0.01);\n",
    "\n",
    "// Create a multi-threaded data loader for the MNIST dataset.\n",
    "auto data_loader = torch::data::make_data_loader(\n",
    "  torch::data::datasets::MNIST(\"../dataset/fashion_mnist\").map(\n",
    "      torch::data::transforms::Stack<>()),\n",
    "  /*batch_size=*/100);\n",
    "\n",
    "\n",
    "\n",
    "for (size_t epoch = 1; epoch <= EPOCH_MAX; ++epoch) {\n",
    "    size_t batch_index = 0;\n",
    "    // Iterate the data loader to yield batches from the dataset.\n",
    "    for (auto& batch : *data_loader) {\n",
    "        // Reset gradients.\n",
    "        optimizer.zero_grad();\n",
    "        // Execute the model on the input data.\n",
    "        torch::Tensor prediction = net(batch.data);\n",
    "        // Compute a loss value to judge the prediction of our model.\n",
    "        torch::Tensor loss = Loss(prediction, batch.target);\n",
    "//         torch::Tensor loss = torch::nll_loss(prediction, batch.target);\n",
    "        // Compute gradients of the loss w.r.t. the parameters of our model.\n",
    "        loss.backward();\n",
    "        // Update the parameters based on the calculated gradients.\n",
    "        optimizer.step();\n",
    "        // Output the loss and checkpoint every 100 batches.\n",
    "        if (++batch_index % 300 == 0) {\n",
    "        std::cout << \"Epoch: \" << epoch << \" | Batch: \" << batch_index\n",
    "                  << \" | Loss: \" << loss.item<float>() << std::endl;\n",
    "        }\n",
    "    }    \n",
    "}\n",
    "\n",
    "std::cout << std::endl << \"\\r\\nTraining finished!\\r\\n\" << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-importance",
   "metadata": {},
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yellow-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "void show_images(std::vector<torch::Tensor> images, std::vector<torch::Tensor> labels, std::string labeltxt[])\n",
    "{\n",
    "    auto a = images;\n",
    "    auto b = labels;\n",
    "\n",
    "    torch::Tensor image1, image2, label;\n",
    "    std::string s1, s2;\n",
    "    for (int i = 0; i < a.size()/2; i++) {\n",
    "        torch::Tensor t1 = a[i].squeeze();\n",
    "        torch::Tensor t2 = a[i+1].squeeze();\n",
    "        if (image1.numel() == 0) {\n",
    "            image1 = t1.clone();\n",
    "            s1 = labeltxt[b[i].item<int>()] + \"\\t\\t\";\n",
    "        } else {\n",
    "            image1 = torch::cat({image1, t1}, 1);\n",
    "            s1 += labeltxt[b[i].item<int>()];\n",
    "            s1 += \"\\t\\t\";\n",
    "        }\n",
    "\n",
    "        if (image2.numel() == 0) {\n",
    "            image2 = t2.clone();\n",
    "            s2 = labeltxt[b[i+1].item<int>()] + \"\\t\\t\";\n",
    "        } else {\n",
    "            image2 = torch::cat({image2, t2}, 1);\n",
    "            s2 += labeltxt[b[i+1].item<int>()];\n",
    "            s2 += \"\\t\\t\";\n",
    "        }\n",
    "    }\n",
    "    \n",
    "//     for (int i = 0; i < b.size()/2; i++) {\n",
    "//         int idx = b[i * 2].item<int>();\n",
    "//         std::cout << labeltxt[idx] << \"\\t\";\n",
    "//     }\n",
    "//     std::cout << std::endl;\n",
    "    \n",
    "//     for (int i = 0; i < b.size()/2; i++) {\n",
    "//         int idx = b[i * 2 + 1].item<int>();\n",
    "//         std::cout << labeltxt[idx] << \"\\t\";\n",
    "//     }\n",
    "//     std::cout << std::endl;\n",
    "    \n",
    "    std::cout << s1 << std::endl;\n",
    "    std::cout << s2 << std::endl;\n",
    "    torch::Tensor image = torch::cat({image1, image2}, 0);\n",
    "    image *= 255;\n",
    "    image = torch::clamp(image, 0, 255);\n",
    "    // 原数据类型为float，为适应cv Mat的数据类型（CV_8UC1），需要转换为unsigned char;\n",
    "    image = image.to(torch::kU8);\n",
    "    cv::Mat img(image.size(0), image.size(1), CV_8UC1);\n",
    "    std::memcpy((void*)img.data, image.data_ptr(), sizeof(torch::kU8)*image.numel());\n",
    "    cv::imwrite(\"test.png\", img);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valid-intensity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images0.sizes() = \n",
      "[12, 1, 28, 28]\n",
      "<<--->>\n",
      "\n",
      "labels0.sizes() = \n",
      "[12]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std::string text_labels[10] = { \"t-shirt\", \"trouser\", \n",
    "                                \"pullover\", \"dress\", \n",
    "                                \"coat\", \"sandal\", \n",
    "                                \"shirt\", \"sneaker\", \n",
    "                                \"bag\", \"ankle boot\"\n",
    "                               };\n",
    "\n",
    "auto data_loader_test = torch::data::make_data_loader(\n",
    "  torch::data::datasets::MNIST(\"../dataset/fashion_mnist\").map(\n",
    "      torch::data::transforms::Stack<>()),\n",
    "  /*batch_size=*/12);\n",
    "\n",
    "auto batch_iter = data_loader_test->begin();\n",
    "auto images0 = (*batch_iter).data;\n",
    "auto labels0 = (*batch_iter).target;\n",
    "\n",
    "/*看一下每个batch的大小*/\n",
    "printT(images0.sizes());\n",
    "printT(labels0.sizes());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dramatic-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sneaker\t\tsandal\t\tsandal\t\tdress\t\tt-shirt\t\tbag\t\t\n",
      "sandal\t\tsandal\t\tdress\t\tt-shirt\t\tbag\t\tbag\t\t\n"
     ]
    },
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* **\n",
    " * images0是batch tensor，是一个四维tensor，其大小为batch_size x channel x height x width\n",
    " * 使用chunk()将其拆散为batch_size个独立tensor，每个tensor是一幅独立图片，然后将这些tensor再组合\n",
    " * 成一个vector<torch::Tensor>;\n",
    " */\n",
    "auto a = torch::chunk(images0, images0.size(0));\n",
    "auto b = torch::chunk(labels0, labels0.size(0));\n",
    "\n",
    "// 取出其中第一幅图像，其大小为 1 x 28 x 28，其中1是通道数\n",
    "auto image = a[0].clone();\n",
    "auto label = b[0].clone();\n",
    "\n",
    "// printT(image.sizes());\n",
    "// 使用squeeze()去除那些大小为1的维度，这里，会把图片的通道维度消除掉，仅剩下长、宽；\n",
    "// permute()函数用于交换不同维度的顺序，这里用不到，如果是3通道图像，tensor的格式为\n",
    "// C X H X W，此时需要借助permute()将其变为 H X W X C;\n",
    "image = image.squeeze();//.permute({1,2,0});\n",
    "// 因为在处理前对cvmat中的值做了归一化，所以现在要*255恢复，同时对于不在0-255范围内的数据，需要做限制\n",
    "image *= 255;\n",
    "image = torch::clamp(image, 0, 255);\n",
    "// 原数据类型为float，为适应cv Mat的数据类型（CV_8UC1），需要转换为unsigned char;\n",
    "image = image.to(torch::kU8);\n",
    "\n",
    "// printT(image);\n",
    "show_images(a, b, text_labels);\n",
    "auto simg = im::image(\"test.png\");\n",
    "simg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mature-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sneaker\t\tsandal\t\tsandal\t\tdress\t\tt-shirt\t\tbag\t\t\n",
      "sandal\t\tsandal\t\tdress\t\tt-shirt\t\tbag\t\tpullover\t\t\n"
     ]
    },
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto result = net(images0);\n",
    "\n",
    "auto tt = result.max(1);\n",
    "auto aa = std::get<0>(tt);\n",
    "auto bb = std::get<1>(tt); //index\n",
    "\n",
    "// printT(aa.dim());\n",
    "// printT(bb.dim());\n",
    "// printT(aa);\n",
    "// printT(bb);\n",
    "\n",
    "auto c = torch::chunk(images0, images0.size(0));\n",
    "auto d = torch::chunk(bb, bb.size(0));\n",
    "show_images(c, d, text_labels);\n",
    "auto simg = im::image(\"test.png\");\n",
    "simg\n",
    "\n",
    "/* \n",
    " * 经过30个轮次的训练，识别结果还是有个别错误\n",
    " */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-oxford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-statistics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-bridges",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-messenger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-agriculture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
