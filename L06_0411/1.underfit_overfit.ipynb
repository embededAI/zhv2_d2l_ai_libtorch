{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "round-dinner",
   "metadata": {},
   "source": [
    "# 使用前，需要先导入需要的头文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../inc/macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../inc/load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../inc/custom_def.hpp\"\n",
    "/*import matplotlibcpp*/\n",
    "#include \"../inc/load_matplotlibcpp.hpp\"\n",
    "/*import opencv*/\n",
    "#include \"../inc/load_opencv.hpp\"\n",
    "\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include <cmath>\n",
    "\n",
    "// Use (void) to silent unused warnings.\n",
    "#define assertm(exp, msg) assert(((void)msg, exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suited-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset : public torch::data::Dataset<MyDataset>\n",
    "{\n",
    "    private:\n",
    "        torch::Tensor states_, labels_;\n",
    "\n",
    "    public:\n",
    "        explicit MyDataset(torch::Tensor states, torch::Tensor labels) \n",
    "            : states_(states),\n",
    "              labels_(labels) {   };\n",
    "\n",
    "        torch::data::Example<> get(size_t index) override {\n",
    "            return {states_[index], labels_[index]};\n",
    "        };\n",
    "\n",
    "        torch::optional<size_t> size() const override {\n",
    "            return states_.size(0);\n",
    "        };\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-cursor",
   "metadata": {},
   "source": [
    "# 模型选择、欠拟合和过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-semiconductor",
   "metadata": {},
   "source": [
    "### 使用以下三阶多项式来生成训练和测试数据的标签\n",
    "\n",
    "$y = 5 + 1.2x - 3.4 \\frac{x^2}{2!} + 5.6 \\frac{x^3}{3!} + \\epsilon \\quad where \\quad\\epsilon \\sim \\mathcal{N} (0,0.01^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civil-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "constexpr int max_degree = 20;\n",
    "constexpr int n_train = 100;\n",
    "constexpr int n_test = 100;\n",
    "\n",
    "//多项式系数\n",
    "torch::Tensor true_w = torch::zeros(max_degree);\n",
    "float temp[] = {5.0, 1.2, -3.4, 5.6};\n",
    "memcpy(true_w.data_ptr(), temp, sizeof(temp));\n",
    "\n",
    "//准备输入\n",
    "torch::Tensor features = torch::randint(-99999, 99999, {n_train + n_test, 1}) / 100000.0;\n",
    "torch::Tensor poly_features  = features.clone();\n",
    "poly_features = poly_features.pow(torch::arange(max_degree));\n",
    "\n",
    "for (int i = 0; i < max_degree; i++) {\n",
    "    int factorial = 1;\n",
    "    if(i != 0) factorial = tgamma(i);\n",
    "    for (int row = 0; row < (n_train + n_test); row++) {\n",
    "        poly_features[row][i] /= factorial;\n",
    "    }\n",
    "}\n",
    "\n",
    "// printT(features);\n",
    "// printT(poly_features);\n",
    "\n",
    "//生成输出\n",
    "true_w = true_w.reshape({max_degree, 1});\n",
    "// printT(true_w);\n",
    "torch::Tensor labels = poly_features.mm(true_w);\n",
    "labels += torch::rand_like(labels) * 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unknown-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}) = \n",
      " 0.6649\n",
      " 0.0729\n",
      "[ CPUFloatType{2,1} ]\n",
      "<<--->>\n",
      "\n",
      "poly_features.index({torch::indexing::Slice(torch::indexing::None, 1, torch::indexing::None)}) = \n",
      "Columns 1 to 6 1.0000e+00  6.6488e-01  4.4207e-01  1.4696e-01  3.2570e-02  5.4138e-03\n",
      "\n",
      "Columns 7 to 12 7.1991e-04  7.9776e-05  7.5773e-06  6.2975e-07  4.6523e-08  3.0932e-09\n",
      "\n",
      "Columns 13 to 18 1.8697e-10  1.0359e-11 -1.5363e-12 -1.0215e-12 -6.7914e-13 -4.5155e-13\n",
      "\n",
      "Columns 19 to 20-3.0023e-13 -1.9961e-13\n",
      "[ CPUFloatType{1,20} ]\n",
      "<<--->>\n",
      "\n",
      "labels.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}) = \n",
      " 5.1738\n",
      " 5.0996\n",
      "[ CPUFloatType{2,1} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printT(features.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    \n",
    "  \n",
    "printT(poly_features.index({torch::indexing::Slice(torch::indexing::None, 1, torch::indexing::None)}));    \n",
    "\n",
    "printT(labels.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-equivalent",
   "metadata": {},
   "source": [
    "### 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exotic-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<int> x;\n",
    "std::vector<double> y;\n",
    "std::vector<double> y_hat;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hairy-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor train(torch::Tensor train_features, \n",
    "           torch::Tensor test_features, \n",
    "           torch::Tensor train_labels, \n",
    "           torch::Tensor test_labels,\n",
    "           int num_epochs = 400,\n",
    "           int batch_size = 10)\n",
    "{\n",
    "    assertm(train_features.dim() == 2, \"train_features should have 2 dims\");\n",
    "    assertm(test_features.dim() == 2, \"test_features should have 2 dims\");\n",
    "    \n",
    "    auto train_data_set = MyDataset(train_features, train_labels)\n",
    "                                    .map(torch::data::transforms::Normalize<>(0, 0.5))\n",
    "                                    .map(torch::data::transforms::Stack<>());\n",
    "    auto test_data_set = MyDataset(test_features, test_labels)\n",
    "                                    .map(torch::data::transforms::Normalize<>(0, 0.5))\n",
    "                                    .map(torch::data::transforms::Stack<>());\n",
    "\n",
    "    auto train_data_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
    "                                    std::move(train_data_set), \n",
    "                                    batch_size);\n",
    "\n",
    "    auto test_data_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
    "                                    std::move(test_data_set), \n",
    "                                    batch_size);\n",
    "\n",
    "    int input_shape = train_features.size(1);\n",
    "    torch::nn::Sequential net({{\"fc\", torch::nn::Linear(torch::nn::LinearOptions(input_shape, 1).bias(false))}});\n",
    "    \n",
    "//     auto p = net->named_parameters(false);\n",
    "//     auto w = p.find(\"weight\");\n",
    "//     auto b = p.find(\"bias\");   \n",
    "    \n",
    "//     //if (w != nullptr) torch::nn::init::xavier_uniform_(*w);\n",
    "//     if (w != nullptr) torch::nn::init::uniform_(*w, -1, 1);\n",
    "//     //if (w != nullptr) torch::nn::init::normal_(*w);\n",
    "//     if (b != nullptr) torch::nn::init::constant_(*b, 0.01);\n",
    "    \n",
    "//     auto optimizer = torch::optim::SGD(net->parameters(), torch::optim::SGDOptions(0.01).momentum(0.5));\n",
    "    auto optimizer = torch::optim::SGD(net->parameters(), /*lr*/0.01);\n",
    "    \n",
    "        \n",
    "    for (int epoch = 0; epoch < num_epochs; epoch++) \n",
    "    {\n",
    "        torch::Tensor loss_values;\n",
    "        if (epoch % 10 == 0) x.push_back(epoch);\n",
    "        \n",
    "        for (auto& batch : *train_data_loader) {\n",
    "            auto data = batch.data;\n",
    "            auto labels = batch.target;\n",
    "\n",
    "//             optimizer.zero_grad();\n",
    "            net->zero_grad();\n",
    "            auto training_prediction = net->forward(data);\n",
    "            loss_values = torch::mse_loss(training_prediction, labels);\n",
    "            loss_values = loss_values.sum() / training_prediction.size(0);\n",
    "            loss_values.backward(); \n",
    "            optimizer.step();\n",
    "        }\n",
    "        if (epoch % 10 == 0) \n",
    "//             y.push_back(loss_values.max().item<double>());\n",
    "            y.push_back(loss_values.sum().item<double>());\n",
    "        \n",
    "        auto test_prediction = net->forward(test_features);\n",
    "        auto test_loss_values = torch::mse_loss(test_prediction, test_labels);\n",
    "        if (epoch % 10 == 0) \n",
    "//             y_hat.push_back(test_loss_values.max().item<double>());        \n",
    "            y_hat.push_back(torch::sum(test_loss_values).item<double>() / test_prediction.size(0));        \n",
    "        \n",
    "        if (epoch % (num_epochs/10) == 0) {\n",
    "        // Report the error with respect to y_training. \n",
    "        double sum_loss = loss_values.sum().item<double>();\n",
    "        std::cout << \"Epoch \" << epoch \n",
    "            << \", sum(loss_values) = \" << sum_loss << std::endl;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    std::cout << net->parameters() << std::endl;\n",
    "    return net->parameters()[0];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceramic-operator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.size(0) = \n",
      "200\n",
      "<<--->>\n",
      "\n",
      "train_data.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}) = \n",
      " 1.0000  0.6649  0.4421  0.1470\n",
      " 1.0000  0.0729  0.0053  0.0002\n",
      "[ CPUFloatType{2,4} ]\n",
      "<<--->>\n",
      "\n",
      "train_label.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}) = \n",
      " 5.1738\n",
      " 5.0996\n",
      "[ CPUFloatType{2,1} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto train_data = \n",
    "    poly_features.index({torch::indexing::Slice(0, n_train, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 4, torch::indexing::None)});\n",
    "auto train_label = \n",
    "    labels.index({torch::indexing::Slice(0, n_train, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 4, torch::indexing::None)});\n",
    "\n",
    "auto test_data = \n",
    "    poly_features.index({torch::indexing::Slice(n_train, torch::indexing::None, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 4, torch::indexing::None)});\n",
    "auto test_label = \n",
    "    labels.index({torch::indexing::Slice(n_train, torch::indexing::None, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 4, torch::indexing::None)});\n",
    "\n",
    "\n",
    "printT(train_data.size(0));\n",
    "printT(train_data.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    \n",
    "printT(train_label.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-attraction",
   "metadata": {},
   "source": [
    "### 训练并验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "english-scientist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, sum(loss_values) = 0.359569\n",
      "Epoch 500, sum(loss_values) = 0.484697\n",
      "Epoch 1000, sum(loss_values) = 0.0976498\n",
      "Epoch 1500, sum(loss_values) = 0.381116\n",
      "Epoch 2000, sum(loss_values) = 0.304709\n",
      "Epoch 2500, sum(loss_values) = 0.366143\n",
      "Epoch 3000, sum(loss_values) = 0.488106\n",
      "Epoch 3500, sum(loss_values) = 0.475553\n",
      "Epoch 4000, sum(loss_values) = 0.546498\n",
      "Epoch 4500, sum(loss_values) = 0.422297\n",
      " 2.0242  0.0663 -0.2096  0.3255\n",
      "[ CPUFloatType{1,4} ]\n"
     ]
    }
   ],
   "source": [
    "auto w = train(train_data, test_data, train_label, test_label, 5000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "//true_w\n",
    "// = {5.0, 1.2, -3.4, 5.6};\n",
    "\n",
    "w = w.reshape({4,1});\n",
    "printT(train_label[0]);\n",
    "printT(train_data[0].reshape({1,4}).mm(w));\n",
    "\n",
    "printT(test_label[3]);\n",
    "printT(test_data[3].reshape({1,4}).mm(w));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-hours",
   "metadata": {},
   "source": [
    "### 训练结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt::semilogy(x, y, \"b\");\n",
    "plt::semilogy(x, y_hat, \"r\");\n",
    "\n",
    "plt::title(\"loss(r:test  b:train)\");\n",
    "plt::legend();\n",
    "plt::save(\"./loss.png\"); \n",
    "plt::show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto img1 = im::image(\"./loss.png\");\n",
    "img1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-accountability",
   "metadata": {},
   "source": [
    "# 欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto train_data = \n",
    "    poly_features.index({torch::indexing::Slice(0, n_train, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 2, torch::indexing::None)});\n",
    "auto train_label = \n",
    "    labels.index({torch::indexing::Slice(0, n_train, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 2, torch::indexing::None)});\n",
    "\n",
    "auto test_data = \n",
    "    poly_features.index({torch::indexing::Slice(n_train, torch::indexing::None, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 2, torch::indexing::None)});\n",
    "auto test_label = \n",
    "    labels.index({torch::indexing::Slice(n_train, torch::indexing::None, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, 2, torch::indexing::None)});\n",
    "\n",
    "\n",
    "printT(train_data.size(0));\n",
    "printT(train_data.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    \n",
    "printT(train_label.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector <int>().swap(x);\n",
    "std::vector <double>().swap(y);\n",
    "std::vector <double>().swap(y_hat);\n",
    "\n",
    "auto w = train(train_data, test_data, train_label, test_label, 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "//true_w\n",
    "// = {5.0, 1.2, -3.4, 5.6};\n",
    "\n",
    "w = w.reshape({2,1});\n",
    "printT(train_label[0]);\n",
    "printT(train_data[0].reshape({1,2}).mm(w));\n",
    "\n",
    "printT(test_label[3]);\n",
    "printT(test_data[3].reshape({1,2}).mm(w));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt::semilogy(x, y, \"b\");\n",
    "plt::semilogy(x, y_hat, \"r\");\n",
    "\n",
    "plt::title(\"loss_underfit(r:test  b:train)\");\n",
    "plt::legend();\n",
    "plt::save(\"./loss_underfit.png\"); \n",
    "plt::show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto img2 = im::image(\"./loss_underfit.png\");\n",
    "img2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-allen",
   "metadata": {},
   "source": [
    "# 过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define W_OVERFIT (20)\n",
    "\n",
    "auto train_data = \n",
    "    poly_features.index({torch::indexing::Slice(0, n_train, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, W_OVERFIT, torch::indexing::None)});\n",
    "auto train_label = \n",
    "    labels.index({torch::indexing::Slice(0, n_train, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, W_OVERFIT, torch::indexing::None)});\n",
    "\n",
    "auto test_data = \n",
    "    poly_features.index({torch::indexing::Slice(n_train, torch::indexing::None, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, W_OVERFIT, torch::indexing::None)});\n",
    "auto test_label = \n",
    "    labels.index({torch::indexing::Slice(n_train, torch::indexing::None, torch::indexing::None),\n",
    "                         torch::indexing::Slice(0, W_OVERFIT, torch::indexing::None)});\n",
    "\n",
    "\n",
    "printT(train_data.size(0));\n",
    "printT(train_data.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    \n",
    "printT(train_label.index({torch::indexing::Slice(torch::indexing::None, 2, torch::indexing::None)}));    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(!x.empty()) std::vector <int>().swap(x);\n",
    "if(!y.empty()) std::vector <double>().swap(y);\n",
    "if(!y_hat.empty()) std::vector <double>().swap(y_hat);\n",
    "\n",
    "auto w = train(train_data, test_data, train_label, test_label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "//true_w\n",
    "// = {5.0, 1.2, -3.4, 5.6};\n",
    "\n",
    "w = w.reshape({W_OVERFIT,1});\n",
    "printT(train_label[0]);\n",
    "printT(train_data[0].reshape({1,W_OVERFIT}).mm(w));\n",
    "\n",
    "printT(test_label[3]);\n",
    "printT(test_data[3].reshape({1,W_OVERFIT}).mm(w));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt::semilogy(x, y, \"b\");\n",
    "plt::semilogy(x, y_hat, \"r\");\n",
    "\n",
    "plt::title(\"loss_overfit(r:test  b:train)\");\n",
    "plt::legend();\n",
    "plt::save(\"./loss_overfit.png\"); \n",
    "plt::show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto img2 = im::image(\"./loss_overfit.png\");\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-surface",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
