{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surface-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../inc/macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../inc/load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../inc/custom_def.hpp\"\n",
    "/*import matplotlibcpp*/\n",
    "#include \"../inc/load_matplotlibcpp.hpp\"\n",
    "/*import opencv*/\n",
    "#include \"../inc/load_opencv.hpp\"\n",
    "\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include <cmath>\n",
    "\n",
    "// Use (void) to silent unused warnings.\n",
    "#define assertm(exp, msg) assert(((void)msg, exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "apart-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define VAR_NAME(Variable) (#Variable)\n",
    "\n",
    "void print_tensor_size(std::string name, torch::Tensor t)\n",
    "{\n",
    "    int dims = t.dim();\n",
    "    std::cout << name << \" dims is (\";\n",
    "    for (int i = 0; i < dims; i++) {\n",
    "        std::cout << t.size(i);\n",
    "        if (i < (dims - 1)) std::cout << \" x \";\n",
    "    }\n",
    "    std::cout << \")\" << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-concert",
   "metadata": {},
   "source": [
    "# 层和块\n",
    "\n",
    "首先，我们回顾一下多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "olive-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::nn::Sequential net(torch::nn::Linear(20, 256),\n",
    "                          torch::nn::ReLU(),\n",
    "                          torch::nn::Linear(256, 10)\n",
    "                         );\n",
    "/* ***\n",
    " * 当然也可以给每个layer加个名字\n",
    " */\n",
    "// torch::nn::Sequential net1({{\"fc1\", torch::nn::Linear(20, 256)},\n",
    "//                           {\"relu1\", torch::nn::ReLU()},\n",
    "//                           {\"fc2\", torch::nn::Linear(256, 10)}}\n",
    "//                          );\n",
    "\n",
    "\n",
    "auto X = torch::rand({2, 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-maker",
   "metadata": {},
   "source": [
    "$\\uparrow\\uparrow\\uparrow\\uparrow\\uparrow$   nn.Sequential定义了一种特殊的Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-victorian",
   "metadata": {},
   "source": [
    "## 自定义块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affiliated-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*design a net*/\n",
    "struct MLP : torch::nn::Module {\n",
    "  MLP() {\n",
    "    // Construct and register two Linear submodules.\n",
    "    hidden = register_module(\"hidden\", torch::nn::Linear(20, 256));\n",
    "    output = register_module(\"output\", torch::nn::Linear(256, 10));\n",
    "  }\n",
    "\n",
    "  // Implement the Net's algorithm.\n",
    "  torch::Tensor forward(torch::Tensor x) {\n",
    "    // Use one of many tensor manipulation functions.\n",
    "    x = hidden->forward(x);\n",
    "    x = torch::relu(x);\n",
    "    x = output->forward(x);\n",
    "    return x;\n",
    "  }\n",
    "\n",
    "  // Use one of many \"standard library\" modules.\n",
    "  torch::nn::Linear hidden{nullptr}, output{nullptr};\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-diesel",
   "metadata": {},
   "source": [
    "实例化多层感知机的层，然后在每次调用正向传播函数时调用这些层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "portuguese-vertical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net->forward(X) = \n",
      " 0.0050 -0.0098 -0.1058  0.1871  0.1308 -0.2072  0.1157  0.0479  0.0384 -0.0533\n",
      " 0.0095  0.0497 -0.2710  0.3096  0.2933 -0.1786  0.1169  0.1132  0.0158 -0.0726\n",
      "[ CPUFloatType{2,10} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Create a new Net.\n",
    "auto net = std::make_shared<MLP>();\n",
    "printT(net->forward(X));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-occurrence",
   "metadata": {},
   "source": [
    "## 顺序块\n",
    "\n",
    "原教程此部分功能类似于torch::nn::Sequential，所以不再赘述；\n",
    "可以参考源码中关于Sequential类的实现：\n",
    "\n",
    "```\n",
    "\n",
    " /// A `ModuleHolder` subclass for `SequentialImpl`.\n",
    "/// See the documentation for `SequentialImpl` class to learn what methods it\n",
    "/// provides, or the documentation for `ModuleHolder` to learn about PyTorch's\n",
    "/// module storage semantics.                                                                                                                                                        \n",
    "class Sequential : public torch::nn::ModuleHolder<SequentialImpl> {\n",
    "public:\n",
    "  using torch::nn::ModuleHolder<SequentialImpl>::ModuleHolder;\n",
    "\n",
    "  Sequential() : ModuleHolder() {}\n",
    "\n",
    "  /// Constructs the `Sequential` from a braced-init-list of named `AnyModule`s.\n",
    "  /// It enables the following use case:\n",
    "  /// `Sequential sequential({{\"m1\", M(1)}, {\"m2\", M(2)}})`\n",
    "  Sequential(std::initializer_list<NamedAnyModule> named_modules) : ModuleHolder(std::make_shared<SequentialImpl>(std::move(named_modules))) {}\n",
    " \n",
    "};\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-cambodia",
   "metadata": {},
   "source": [
    "在正向传播函数中执行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modern-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*design a net*/\n",
    "struct FixedHiddenMLP : torch::nn::Module {\n",
    "    FixedHiddenMLP() {\n",
    "        rand_weight = torch::rand({20, 20}, torch::requires_grad(false));\n",
    "        linear = register_module(\"linear\", torch::nn::Linear(20, 20));\n",
    "    }\n",
    "\n",
    "    // Implement the FixedHiddenMLP's algorithm.\n",
    "    torch::Tensor forward(torch::Tensor x) {\n",
    "        // Use one of many tensor manipulation functions.\n",
    "        x = linear->forward(x);\n",
    "        x = torch::relu(torch::mm(x, rand_weight)+1);\n",
    "        x = linear->forward(x);\n",
    "        while (x.abs().sum().item<float>() > 1) {\n",
    "            x /= 2;\n",
    "        }\n",
    "        \n",
    "        return x.sum();\n",
    "    }\n",
    "\n",
    "  // Use one of many \"standard library\" modules.\n",
    "  torch::Tensor rand_weight;\n",
    "  torch::nn::Linear linear{nullptr};\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blank-warrior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net3->forward(X) = \n",
      "-0.0140377\n",
      "[ CPUFloatType{} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Create a new Net.\n",
    "auto net3 = std::make_shared<FixedHiddenMLP>();\n",
    "printT(net3->forward(X));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-ranch",
   "metadata": {},
   "source": [
    "## 混合搭配各种组合块的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lucky-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*design a net*/\n",
    "struct NestMLP : torch::nn::Module {\n",
    "    NestMLP() {\n",
    "        net = torch::nn::Sequential(torch::nn::Linear(20, 64),\n",
    "                                    torch::nn::ReLU(),\n",
    "                                    torch::nn::Linear(64, 32),\n",
    "                                    torch::nn::ReLU());\n",
    "        linear = torch::nn::Linear(32, 16);\n",
    "    }\n",
    "\n",
    "    // Implement the Net's algorithm.\n",
    "    torch::Tensor forward(torch::Tensor x) {\n",
    "        x = linear->forward(net->forward(x));\n",
    "        return x;\n",
    "    }\n",
    "\n",
    "    // Use one of many \"standard library\" modules.\n",
    "    torch::nn::Sequential net{nullptr};\n",
    "    torch::nn::Linear linear{nullptr};\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indoor-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chimera->forward(X) = \n",
      "-0.113716\n",
      "[ CPUFloatType{} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto chimera = torch::nn::Sequential(NestMLP(), \n",
    "                                torch::nn::Linear(16, 20), \n",
    "                                FixedHiddenMLP());\n",
    "printT(chimera->forward(X));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-lending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
