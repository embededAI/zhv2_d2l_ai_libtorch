{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cheap-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../inc/macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../inc/load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../inc/custom_def.hpp\"\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-dinner",
   "metadata": {},
   "source": [
    "# 1.创建一个Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-project",
   "metadata": {},
   "source": [
    "## 1.1 创建一个新的Tensor，以empty函数为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.2420e+18\n",
      " 7.0184e+18\n",
      " 7.8127e+18\n",
      "[ CPULongType{3} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t1 = torch::empty(3, torch::kInt64);\n",
    "\n",
    "std::cout << t1 << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exclusive-tennessee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.2777e-06\n",
      " 4.5864e-41\n",
      " 1.2777e-06\n",
      "[ CPUFloatType{3} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t1 = torch::empty(3, torch::kCPU);\n",
    "\n",
    "std::cout << t1 << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handmade-research",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.2971e+08  1.7179e+09  1.9533e+09  1.8186e+09  1.2314e+09  1.1639e+09\n",
      " 8.2649e+08  8.4432e+08  1.5972e+09  1.9497e+09  1.7513e+09  1.9538e+09\n",
      " 1.6349e+09  1.0938e+09  1.7354e+09  1.2984e+09  1.1640e+09  8.2853e+08\n",
      " 1.3299e+09  1.4145e+09 -1.6753e+07 -1.0000e+00  1.1300e+02  0.0000e+00\n",
      " 1.5508e+09  2.2084e+04  1.5529e+09  2.2084e+04  1.5514e+09  2.2084e+04\n",
      "[ CPUIntType{5,6} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t2 = torch::empty({5,6}, torch::kInt32);\n",
    "std::cout << t2 << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "female-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 = \n",
      " 3.1579e+03\n",
      " 7.7242e-10\n",
      " 6.6971e+31\n",
      "[ CPUFloatType{3} ]\n",
      "\n",
      "t2 = \n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CUDAFloatType{3,4} ]\n",
      "\n",
      "t3 = \n",
      " 5.7680e+08\n",
      " 1.9365e+09\n",
      " 2.0377e+09\n",
      "[ CPUIntType{3} ]\n",
      "\n",
      "t4 = \n",
      "[ SparseCPUFloatType{}\n",
      "indices:\n",
      "[ CPULongType{2,0} ]\n",
      "values:\n",
      "[ CPUFloatType{0} ]\n",
      "size:\n",
      "[3, 4]\n",
      "]\n",
      "\n",
      "t5 = \n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CUDAByteType{3,4} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Device dev_cpu(torch::kCPU);\n",
    "/*因为只有一块1060，因此index只能填0，填其它值会报错*/\n",
    "/*macbook pro就不要尝试了，因为你没有cuda！*/\n",
    "torch::Device dev_gpu(torch::kCUDA, 0/*device index*/);\n",
    "\n",
    "torch::ScalarType dtype_int(torch::kInt);\n",
    "\n",
    "at::IntArrayRef m_iar_1({3}); \n",
    "at::IntArrayRef m_iar_2({3,4}); \n",
    "at::ArrayRef<int64_t> m_ar_1({3});\n",
    "at::ArrayRef<int64_t> m_ar_2({3,4});\n",
    "\n",
    "torch::Tensor t1 = torch::empty(m_iar_1, dev_cpu);\n",
    "std::cout << \"t1 = \" << std::endl << t1 << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor t2 = torch::empty(m_ar_2, dev_gpu);\n",
    "std::cout << \"t2 = \" << std::endl << t2 << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor t3 = torch::empty(m_ar_1, dtype_int);\n",
    "std::cout << \"t3 = \" << std::endl << t3 << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor t4 = torch::empty(m_iar_2, torch::kSparse);\n",
    "std::cout << \"t4 = \" << std::endl << t4 << std::endl << std::endl;\n",
    "\n",
    "\n",
    "torch::Tensor t5 = torch::empty(m_iar_2, at::device(at::kCUDA).dtype(torch::kByte));\n",
    "std::cout << \"t5 = \" << std::endl << t5 << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-stocks",
   "metadata": {},
   "source": [
    "## 1.2 创建值为0的tensor，使用zeros(...)函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-public",
   "metadata": {},
   "source": [
    "同torch::empty(...)函数一样，torch::zeros(...)函数的定义也是位于`{pytorch}/torch/csrc/autograd/generated/variable_factories.h`文件中，具体调用的，还是at::zeros(...)函数，其具体实现位于`{pytorch}/aten/src/ATen/native/TensorFactoryies.cpp`，大致的调用方式是torch::zeros(...) -> at::zeros(...) -> at::native::full(...) -> at::empty(...).fill_(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "local-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[ CPUFloatType{3} ]\n",
      "y = \n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CPUIntType{3,4} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::zeros(3);\n",
    "std::cout << \"x = \" << std::endl << x << std::endl;\n",
    "\n",
    "torch::Tensor y = torch::zeros({3, 4}, torch::kInt);\n",
    "std::cout << \"y = \" << std::endl << y << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-mistake",
   "metadata": {},
   "source": [
    "## 1.3 创建值为1的tensor，使用ones(...)函数\n",
    "\n",
    "关于 ones(...) 的实现，参见 `{pytorch}/aten/src/ATen/native/TensorFactoryies.cpp`；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "functional-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[ CPUFloatType{5} ]\n",
      "<<--->>\n",
      "\n",
      "y = \n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[ CPUIntType{3,4} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::ones(5);\n",
    "printT(x);\n",
    "\n",
    "torch::Tensor y = torch::ones({3, 4}, torch::kInt);\n",
    "printT(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-labor",
   "metadata": {},
   "source": [
    "## 1.4 创建值为随机数的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rolled-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.3523  0.9210  0.9317  0.8193\n",
      " 0.4069  0.3971  0.3080  0.7800\n",
      " 0.0256  0.0208  0.7285  0.0657\n",
      "[ CPUFloatType{3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      " 0.2898  0.7828  0.5083  0.6370\n",
      " 0.2405  0.8166  0.7028  0.7808\n",
      " 0.6381  0.2971  0.3806  0.3117\n",
      "[ CPUDoubleType{3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      "(1,.,.) = \n",
      " -0.2022 -1.3062  1.1624 -0.3078\n",
      "  0.0756 -0.8598  1.0082 -0.1327\n",
      " -0.2754 -0.2268 -2.2643  1.5656\n",
      "\n",
      "(2,.,.) = \n",
      "  0.2290 -0.4580 -0.5440  0.1151\n",
      "  0.3492  1.1893 -1.3065 -0.2194\n",
      " -0.4207  0.1949  0.6551  1.5457\n",
      "\n",
      "(3,.,.) = \n",
      " -0.0411 -1.1133 -0.0861 -1.1201\n",
      "  0.7853  0.4487 -0.6896  0.6812\n",
      "  0.7853 -0.6206  0.7613 -0.6682\n",
      "\n",
      "(4,.,.) = \n",
      " -0.2043  0.5549  0.5182 -0.8192\n",
      " -1.4479  0.5386 -1.5750  0.1939\n",
      "  0.3653 -1.2877  1.6811 -0.4075\n",
      "\n",
      "(5,.,.) = \n",
      " -0.7452 -0.6870  0.5630 -0.4402\n",
      "  0.2659  0.7501  0.6897 -0.8028\n",
      "  0.7229 -2.6378  1.5662 -1.0126\n",
      "[ CPUFloatType{5,3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      "a = \n",
      " 6\n",
      " 6\n",
      " 5\n",
      " 7\n",
      "[ CPUIntType{4} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::rand({3, 4});\n",
    "std::cout << x << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor y = torch::rand({3, 4}, torch::kFloat64);\n",
    "std::cout << y << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor z = torch::randn({5, 3, 4}, torch::kFloat32);\n",
    "std::cout << z << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor a = torch::randint(1/*low*/, 10/*high*/, {4}/*size*/, torch::kInt32);\n",
    "std::cout << \"a = \" << std::endl << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-comparative",
   "metadata": {},
   "source": [
    "## 1.5 根据已有tensor创建新的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imperial-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      " 6  6  6\n",
      " 6  6  6\n",
      " 6  6  6\n",
      "[ CPUFloatType{3,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t = torch::ones({3,3});\n",
    "t += 5;\n",
    "\n",
    "torch::Tensor a(t);\n",
    "std::cout << \"a = \" << std::endl << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "respective-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9529 -0.1274  0.2493\n",
      " 1.1422 -1.5271  0.7417\n",
      " 0.9030  0.2625 -0.9188\n",
      " 1.0648  0.2943 -0.4224\n",
      " 0.5667  0.7336 -0.8017\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor a = torch::ones({5,3});\n",
    "a = torch::randn_like(a);\n",
    "\n",
    "std::cout << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-mediterranean",
   "metadata": {},
   "source": [
    "更多例子请参考 [Tensor Creation API](https://pytorch.org/cppdocs/notes/tensor_creation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-sapphire",
   "metadata": {},
   "source": [
    "# 2. Tensor的相关操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-rates",
   "metadata": {},
   "source": [
    "## 2.1 加法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "national-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[ CPUFloatType{5,3} ]\n",
      "\n",
      "y =\n",
      " 0.3882  0.3528  0.1821\n",
      " 0.5968  2.2406 -1.2372\n",
      " 0.8452  1.0309 -1.0613\n",
      " 1.3290 -0.4286  1.5092\n",
      " 0.2170  0.3363 -0.1296\n",
      "[ CPUFloatType{5,3} ]\n",
      "\n",
      "x+y =\n",
      " 1.3882  1.3528  1.1821\n",
      " 1.5968  3.2406 -0.2372\n",
      " 1.8452  2.0309 -0.0613\n",
      " 2.3290  0.5714  2.5092\n",
      " 1.2170  1.3363  0.8704\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n",
      "torch::add(x,y) =\n",
      " 1.3882  1.3528  1.1821\n",
      " 1.5968  3.2406 -0.2372\n",
      " 1.8452  2.0309 -0.0613\n",
      " 2.3290  0.5714  2.5092\n",
      " 1.2170  1.3363  0.8704\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n",
      "y.add_(x) =\n",
      " 1.3882  1.3528  1.1821\n",
      " 1.5968  3.2406 -0.2372\n",
      " 1.8452  2.0309 -0.0613\n",
      " 2.3290  0.5714  2.5092\n",
      " 1.2170  1.3363  0.8704\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::ones({5,3});\n",
    "torch::Tensor y = torch::randn({5,3});\n",
    "\n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"y =\" << std::endl;\n",
    "std::cout << (y) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"x+y =\" << std::endl;\n",
    "std::cout << (x+y) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"torch::add(x,y) =\" << std::endl;\n",
    "std::cout << torch::add(x,y) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"y.add_(x) =\" << std::endl;\n",
    "std::cout << y.add_(x) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-essence",
   "metadata": {},
   "source": [
    "## 2.2 索引\n",
    "借助于torch::Tensor::index()和torch::Tensor::index_put_()函数，我们可以在libtorch中实现类似pytorch中对tensor的切片存取操作。具体说明详见[tensor_indexing](https://pytorch.org/cppdocs/notes/tensor_indexing.html)页面."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compliant-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[None]=\n",
      " 0  1  2  3  4\n",
      "[ CPUFloatType{1,5} ]\n",
      "\n",
      "(in python) x[Ellipsis, ...]=\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[3]=\n",
      "3\n",
      "[ CPUFloatType{} ]\n",
      "\n",
      "(in python) x[True, False]=\n",
      "[ CPUFloatType{0,5} ]\n",
      "\n",
      "(in python) x[1::2]=\n",
      " 1\n",
      " 3\n",
      "[ CPUFloatType{2} ]\n",
      "\n",
      "(in python) x[::2]=\n",
      " 0\n",
      " 2\n",
      " 4\n",
      "[ CPUFloatType{3} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define SIZE (5)\n",
    "\n",
    "torch::Tensor x = torch::zeros(SIZE);\n",
    "\n",
    "for (int i = 0; i < SIZE; i++) {\n",
    "    x[i] = i;\n",
    "}\n",
    "    \n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "/* *\n",
    " *  Getter ops\n",
    " */\n",
    "std::cout << \"(in python) x[None]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::None})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[Ellipsis, ...]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Ellipsis, \"...\"})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[3]=\" << std::endl;\n",
    "std::cout << (x.index({3})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[True, False]=\" << std::endl;\n",
    "std::cout << (x.index({true,false,true,false,true,false,true,false,true,false,false,true,false,true,false})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[1::2]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Slice(1, torch::indexing::None, 2)})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[::2]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Slice(torch::indexing::None, torch::indexing::None, 2)})) << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "later-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[None] = 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[Ellipsis, ...] = 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[3] = 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[True, False] = 4\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[1::2] = 5\n",
      " 2\n",
      " 5\n",
      " 2\n",
      " 5\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[::2] = 6\n",
      " 6\n",
      " 5\n",
      " 6\n",
      " 5\n",
      " 6\n",
      "[ CPUFloatType{5} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define SIZE (5)\n",
    "\n",
    "torch::Tensor x = torch::zeros(SIZE);\n",
    "\n",
    "for (int i = 0; i < SIZE; i++) {\n",
    "    x[i] = i;\n",
    "}\n",
    "    \n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "/* *\n",
    " *  Setter ops\n",
    " */\n",
    "std::cout << \"(in python) x[None] = 1\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::None}, 1)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[Ellipsis, ...] = 2\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::Ellipsis, \"...\"}, 2)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[3] = 3\" << std::endl;\n",
    "std::cout << (x.index_put_({3}, 3)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[True, False] = 4\" << std::endl;\n",
    "std::cout << (x.index_put_({true,false,true,false,true,false,true,false,true,false,false,true,false,true,false}, 4)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[1::2] = 5\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::Slice(1, torch::indexing::None, 2)}, 5)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[::2] = 6\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::Slice(torch::indexing::None, torch::indexing::None, 2)}, 6)) << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-jaguar",
   "metadata": {},
   "source": [
    "### Python 与 C++ 索引类型对照表\n",
    "\n",
    "|Python | C++ (assuming using namespace torch::indexing) |\n",
    "|:---|:---|\n",
    "|None|None|\n",
    "|Ellipsis|Ellipsis|\n",
    "|...|\"...\"|\n",
    "|123|123|\n",
    "|True|true|\n",
    "|False|false|\n",
    "|: or ::|Slice() or Slice(None, None) or Slice(None, None, None)|\n",
    "|1: or 1::|Slice(1, None) or Slice(1, None, None)|\n",
    "|:3 or :3:|Slice(None, 3) or Slice(None, 3, None)|\n",
    "|::2|Slice(None, None, 2)|\n",
    "|1:3|Slice(1, 3)|\n",
    "|1::2|Slice(1, None, 2)|\n",
    "|:3:2|Slice(None, 3, 2)|\n",
    "|1:3:2|Slice(1, 3, 2)|\n",
    "|torch.tensor([1, 2])|torch::tensor({1, 2})|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-tuner",
   "metadata": {},
   "source": [
    "### 其它索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "material-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "  0   1   2   3\n",
      "  4   5   6   7\n",
      "  8   9  10  11\n",
      "[ CPUFloatType{3,4} ]\n",
      "\n",
      "<<< tensor.index_select >>>\n",
      " 1\n",
      " 2\n",
      "[ CPULongType{2} ]\n",
      "\n",
      "x.index_select(dim = 0, index = idx) =\n",
      "  4   5   6   7\n",
      "  8   9  10  11\n",
      "[ CPUFloatType{2,4} ]\n",
      "\n",
      "x.index_select(dim = 1, index = idx) =\n",
      "  1   2\n",
      "  5   6\n",
      "  9  10\n",
      "[ CPUFloatType{3,2} ]\n",
      "\n",
      "<<< tensor.masked_select >>>\n",
      " 0  0  0  0\n",
      " 0  0  1  1\n",
      " 1  1  1  1\n",
      "[ CPUBoolType{3,4} ]\n",
      "\n",
      "x.masked_select(mask = mask) =\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      " 10\n",
      " 11\n",
      "[ CPUFloatType{6} ]\n",
      "\n",
      "<<< tensor.nonzero >>>\n",
      "注意，返回值是非零元素下标，即x,y \n",
      "x.nonzero() =\n",
      " 0  1\n",
      " 0  2\n",
      " 0  3\n",
      " 1  0\n",
      " 1  1\n",
      " 1  2\n",
      " 1  3\n",
      " 2  0\n",
      " 2  1\n",
      " 2  2\n",
      " 2  3\n",
      "[ CPULongType{11,2} ]\n",
      "\n",
      "<<< tensor.gather >>>\n",
      "注意，index tensor必须指明类型为int64\n",
      " 4  5\n",
      " 4  5\n",
      "[ CPUFloatType{2,2} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::zeros({3,4});\n",
    "\n",
    "for (int i = 0; i < 3; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "        x[i][j] = i*4+j;\n",
    "    }\n",
    "}\n",
    "    \n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "/** Warning:\n",
    " *  a known issue: with xeus-cling, if you call torch::from_blob,\n",
    " *  there will be a link error, \n",
    " *  \n",
    " *  IncrementalExecutor::executeFunction: \n",
    " *  symbol '__emutls_v._ZSt11__once_call' unresolved \n",
    " *  while linking function '_GLOBAL__sub_I_cling_module_8'!\n",
    " *\n",
    " *\n",
    " *  so I write this example in pure \n",
    " *  c++ code in folder : 'cpp_project/basic_ops'.\n",
    " */\n",
    "// std::vector<int32_t> v = {1,2,7,8}; \n",
    "// auto idx = torch::from_blob(v.data(), v.size(), torch::kInt32);\n",
    "\n",
    "\n",
    "std::cout << \"<<< tensor.index_select >>>\" << std::endl;\n",
    "torch::Tensor idx = torch::arange(1,3);\n",
    "std::cout << (idx) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"x.index_select(dim = 0, index = idx) =\" << std::endl;\n",
    "std::cout << (x.index_select(0,idx)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"x.index_select(dim = 1, index = idx) =\" << std::endl;\n",
    "std::cout << (x.index_select(1,idx)) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "std::cout << \"<<< tensor.masked_select >>>\" << std::endl;\n",
    "torch::Tensor mask = x > 5;\n",
    "std::cout << (mask) << std::endl << std::endl;\n",
    "std::cout << \"x.masked_select(mask = mask) =\" << std::endl;\n",
    "std::cout << (x.masked_select(mask)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"<<< tensor.nonzero >>>\" << std::endl;\n",
    "std::cout << \"注意，返回值是非零元素下标，即x,y \"<< std::endl << \"x.nonzero() =\" << std::endl;\n",
    "std::cout << (x.nonzero()) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"<<< tensor.gather >>>\" << std::endl;\n",
    "std::cout << \"注意，index tensor必须指明类型为int64\" << std::endl;\n",
    "torch::Tensor g = torch::ones({2,2}, torch::kInt64);\n",
    "std::cout << (x.gather(0, g)) << std::endl << std::endl;\n",
    "// std::cout << (torch::gather(x, 0, g, false)) << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-cannon",
   "metadata": {},
   "source": [
    "## 2.3 广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "minor-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a+b) = \n",
      " 3  3  3\n",
      " 3  3  3\n",
      " 3  3  3\n",
      "[ CPUFloatType{3,3} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor a = torch::ones({1,3});\n",
    "torch::Tensor b = torch::ones({3,1});\n",
    "\n",
    "b = b + 1;\n",
    "\n",
    "printT((a+b));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-request",
   "metadata": {},
   "source": [
    "\n",
    "## 2.4 改变形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "royal-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      "  0   1   2\n",
      "  3   4   5\n",
      "  6   7   8\n",
      "  9  10  11\n",
      " 12  13  14\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<--->>\n",
      "\n",
      "y = \n",
      "  0   1   2   3   4\n",
      "  5   6   7   8   9\n",
      " 10  11  12  13  14\n",
      "[ CPUFloatType{3,5} ]\n",
      "<<--->>\n",
      "\n",
      "x.resize_({1, w*h}) = \n",
      "  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14\n",
      "[ CPUFloatType{1,15} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "/* *\n",
    " *  Change shapes\n",
    " */\n",
    "constexpr int w = 3;\n",
    "constexpr int h = 5;\n",
    "torch::Tensor x = torch::zeros({h,w});\n",
    "\n",
    "for (int i = 0; i < h; i++) {\n",
    "    for (int j = 0; j < w; j++) {\n",
    "        x[i][j] = i*w+j;\n",
    "    }\n",
    "}\n",
    "\n",
    "printT(x);\n",
    "\n",
    "torch::Tensor y = x.view({w, -1});\n",
    "printT(y);\n",
    "\n",
    "\n",
    "/*\n",
    " * resize_(...) 参见 ATen/native/Resize.cpp\n",
    " */\n",
    "printT(x.resize_({1, w*h}));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
