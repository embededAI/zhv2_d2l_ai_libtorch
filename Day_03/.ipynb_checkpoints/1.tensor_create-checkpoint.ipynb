{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../inc/macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../inc/load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../inc/custom_def.hpp\"\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-dinner",
   "metadata": {},
   "source": [
    "# 1.创建一个Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-project",
   "metadata": {},
   "source": [
    "## 1.1 创建一个新的Tensor，以empty函数为例："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-survey",
   "metadata": {},
   "source": [
    "### 基础操作，使用官方API\n",
    "\n",
    "从 [libtorch的c++ API文档](https://pytorch.org/cppdocs/index.html) 中可以得知，torch::empty()函数接口定义如下：        \n",
    "\n",
    "![torch_empty function](./images/tensor_torch_empty.png)\n",
    "\n",
    "主要是两个参数：IntArrayRef和TensorOptions。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electrical-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.3737e+18\n",
      " 8.3917e+18\n",
      " 5.0590e+18\n",
      "[ CPULongType{3} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t1 = torch::empty(3, torch::kInt64);\n",
    "\n",
    "std::cout << t1 << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exclusive-tennessee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1741e-19\n",
      " 4.5817e-41\n",
      "-1.1741e-19\n",
      "[ CPUFloatType{3} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t1 = torch::empty(3, torch::kCPU);\n",
    "\n",
    "std::cout << t1 << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "handmade-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.8699e+09  9.4637e+08  1.8699e+09  1.6841e+09  1.9672e+09  1.9194e+09\n",
      " 1.6996e+09  1.3971e+09  1.3973e+09  1.9843e+09  1.3977e+09  1.5994e+09\n",
      " 1.1639e+09  2.1760e+04  9.7000e+01  0.0000e+00 -1.1693e+09  2.1879e+04\n",
      "-1.1714e+09  2.1879e+04  1.9516e+09  1.6676e+09  1.2322e+09  1.7150e+09\n",
      " 1.9527e+09  1.2320e+09  1.6307e+09  1.7000e+09  1.9199e+09  1.3974e+09\n",
      "[ CPUIntType{5,6} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t2 = torch::empty({5,6}, torch::kInt32);\n",
    "std::cout << t2 << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-citation",
   "metadata": {},
   "source": [
    "### 深入一点了解，参数类型是怎么回事？\n",
    "\n",
    "咋一看，上面例子中的参数貌似跟API函数中描述的并不一样，对于第一个参数，3显然是个整数，跟IntArrayRef如何关联？ 对于第二个参数，torch::kCPU是Device枚举类型，torch::kInt64是ScalarType枚举类型，好像与TensorOptions风牛马不相及，关于这些问题，我们就得看看相关参数类型的定义了：\n",
    "\n",
    "#### IntArrayRef(c10/util/ArrayRef.h:274)\n",
    "\n",
    "```\n",
    "using IntArrayRef = ArrayRef<int64_t>;\n",
    "\n",
    "\n",
    "/// Construct an ArrayRef from a std::array\n",
    "template <size_t N>\n",
    "/* implicit */ constexpr ArrayRef(const std::array<T, N>& Arr)\n",
    "  : Data(Arr.data()), Length(N) {}\n",
    "\n",
    "/// Construct an ArrayRef from a C array.\n",
    "template <size_t N>\n",
    "/* implicit */ constexpr ArrayRef(const T (&Arr)[N]) : Data(Arr), Length(N) {}\n",
    "```\n",
    "\n",
    "***可见IntArrayRef本质上还是一个int64的list，并且可以从std array或者c array进行构造***\n",
    "\n",
    "---\n",
    "\n",
    "#### TensorOptions(c10/core/TensorOptions.h)\n",
    "\n",
    "```\n",
    "/// Constructs a `TensorOptions` object with the given layout.\n",
    "/* implicit */ TensorOptions(Layout layout) : TensorOptions() {\n",
    "this->set_layout(layout);\n",
    "}\n",
    "\n",
    "/// Constructs a `TensorOptions` object with the given device.\n",
    "/// See NOTE [ TensorOptions Constructors ] on why this is templatized.\n",
    "template<typename T,\n",
    "       typename = std::enable_if_t<std::is_same<std::decay_t<T>, Device>::value>>\n",
    "/* implicit */ TensorOptions(T&& device) : TensorOptions() {\n",
    "this->set_device(std::forward<T>(device));\n",
    "}\n",
    "\n",
    "/// legacy constructor to support ScalarType\n",
    "/* implicit */ TensorOptions(ScalarType dtype) : TensorOptions() {\n",
    "this->set_dtype(dtype);\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "***TensorOptions的隐式构造函数支持从Layout、Device和ScalarType三种枚举类型参数去进行构建，所以我们看到的上述例子也是OK的；***\n",
    "\n",
    "---\n",
    "\n",
    "*下面我们就根据上述API描述的参数来生成几个tensor：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "female-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 = \n",
      " 4.5840e+30\n",
      " 6.0621e+22\n",
      " 3.1581e+03\n",
      "[ CPUFloatType{3} ]\n",
      "\n",
      "t2 = \n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CUDAFloatType{3,4} ]\n",
      "\n",
      "t3 = \n",
      " 9.6267e+08\n",
      " 1.7179e+09\n",
      " 5.7386e+08\n",
      "[ CPUIntType{3} ]\n",
      "\n",
      "t4 = \n",
      "[ SparseCPUFloatType{}\n",
      "indices:\n",
      "[ CPULongType{2,0} ]\n",
      "values:\n",
      "[ CPUFloatType{0} ]\n",
      "size:\n",
      "[3, 4]\n",
      "]\n",
      "\n",
      "t5 = \n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CUDAByteType{3,4} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Device dev_cpu(torch::kCPU);\n",
    "/*因为只有一块1060，因此index只能填0，填其它值会报错*/\n",
    "/*macbook pro就不要尝试了，因为你没有cuda！*/\n",
    "torch::Device dev_gpu(torch::kCUDA, 0/*device index*/);\n",
    "\n",
    "torch::ScalarType dtype_int(torch::kInt);\n",
    "\n",
    "at::IntArrayRef m_iar_1({3}); \n",
    "at::IntArrayRef m_iar_2({3,4}); \n",
    "at::ArrayRef<int64_t> m_ar_1({3});\n",
    "at::ArrayRef<int64_t> m_ar_2({3,4});\n",
    "\n",
    "torch::Tensor t1 = torch::empty(m_iar_1, dev_cpu);\n",
    "std::cout << \"t1 = \" << std::endl << t1 << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor t2 = torch::empty(m_ar_2, dev_gpu);\n",
    "std::cout << \"t2 = \" << std::endl << t2 << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor t3 = torch::empty(m_ar_1, dtype_int);\n",
    "std::cout << \"t3 = \" << std::endl << t3 << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor t4 = torch::empty(m_iar_2, torch::kSparse);\n",
    "std::cout << \"t4 = \" << std::endl << t4 << std::endl << std::endl;\n",
    "\n",
    "\n",
    "torch::Tensor t5 = torch::empty(m_iar_2, at::device(at::kCUDA).dtype(torch::kByte));\n",
    "std::cout << \"t5 = \" << std::endl << t5 << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-ethiopia",
   "metadata": {},
   "source": [
    "### 再深入一点，这个empty(...)函数到底是在哪里定义的？\n",
    "\n",
    "在文件 {pytorch}/aten/src/ATen/native/TensorFactories.cpp 中，可以看到empty(...)的定义：\n",
    "\n",
    "```\n",
    "Tensor empty(\n",
    "    IntArrayRef size,\n",
    "    at::optional<DimnameList> names,\n",
    "    const TensorOptions& options,\n",
    "    optional<MemoryFormat> optional_memory_format) {\n",
    "  if (!names.has_value()) {\n",
    "    return at::empty(size, options, optional_memory_format);\n",
    "  }\n",
    "  TORCH_CHECK(options.layout() == Layout::Strided,\n",
    "      \"NYI: named tensors only support strided layout\");\n",
    "  TORCH_CHECK(options.device().type() == DeviceType::CPU || options.device().type() == DeviceType::CUDA,\n",
    "      \"NYI: named tensors only support CPU and CUDA tensors\");\n",
    "  auto result = at::empty(size, options, optional_memory_format);\n",
    "  internal_set_names_inplace(result, names);\n",
    "  return result;\n",
    "}\n",
    "```\n",
    "\n",
    "但是里面依然调用了at::empty(...)函数，这是怎么回事？？？\n",
    "其实奥秘在 {pytorch}/aten/src/ATen/native/native_functions.yaml 中：\n",
    "\n",
    "![empty def](./images/tensor_torch_empty_impl.png)\n",
    "\n",
    "原来，针对不同的设备（device），empty(...)有不同的定义，显然，对于我们上面大多数例子而言，我们最终调用的其实是empty_cpu(...)函数。\n",
    "这个函数就定义在 {pytorch}/aten/src/ATen/native/TensorFactories.cpp 中：\n",
    "\n",
    "\n",
    "```\n",
    "// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ empty ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Tensor empty_cpu(IntArrayRef size, const TensorOptions& options_, c10::optional<c10::MemoryFormat> optional_memory_format) {\n",
    "\n",
    "  TORCH_CHECK(\n",
    "    !(options_.has_memory_format() && optional_memory_format.has_value()),\n",
    "    \"Cannot set memory_format both in TensorOptions and explicit argument; please delete \"\n",
    "    \"the redundant setter.\");\n",
    "  TensorOptions options = options_.merge_in(TensorOptions().memory_format(optional_memory_format));\n",
    "\n",
    "  AT_ASSERT(options.device().type() == DeviceType::CPU);\n",
    "  TORCH_INTERNAL_ASSERT(impl::variable_excluded_from_dispatch());\n",
    "  check_size_nonnegative(size);\n",
    "\n",
    "  c10::Allocator* allocator;\n",
    "  if (options.pinned_memory()) {\n",
    "    allocator = detail::getCUDAHooks().getPinnedMemoryAllocator();\n",
    "  } else {\n",
    "    allocator = at::getCPUAllocator();\n",
    "  }\n",
    "\n",
    "  int64_t nelements = prod_intlist(size);\n",
    "  auto dtype = options.dtype();\n",
    "  int64_t size_bytes = nelements * dtype.itemsize();\n",
    "  auto storage_impl = c10::make_intrusive<StorageImpl>(\n",
    "      c10::StorageImpl::use_byte_size_t(),\n",
    "      size_bytes,\n",
    "      allocator->allocate(size_bytes),\n",
    "      allocator,\n",
    "      /*resizeable=*/true);\n",
    "\n",
    "  auto tensor = detail::make_tensor<TensorImpl>(\n",
    "      std::move(storage_impl), at::DispatchKey::CPU, dtype);\n",
    "  // Default TensorImpl has size [0]\n",
    "  if (size.size() != 1 || size[0] != 0) {\n",
    "    tensor.unsafeGetTensorImpl()->set_sizes_contiguous(size);\n",
    "  }\n",
    "\n",
    "  auto memory_format = options.memory_format_opt().value_or(MemoryFormat::Contiguous);\n",
    "  tensor.unsafeGetTensorImpl()->empty_tensor_restride(memory_format);\n",
    "\n",
    "  return tensor;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "简单看一下上述代码实现，empty(...)会用到TensorImpl类，另外，native_functions.yaml 中的声明如何与不同的设备实现函数对应上的，此处不在细纠，后续有时间我们再补完；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-stocks",
   "metadata": {},
   "source": [
    "## 1.2 创建值为0的tensor，使用zeros(...)函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-public",
   "metadata": {},
   "source": [
    "同torch::empty(...)函数一样，torch::zeros(...)函数的定义也是位于`{pytorch}/torch/csrc/autograd/generated/variable_factories.h`文件中，具体调用的，还是at::zeros(...)函数，其具体实现位于`{pytorch}/aten/src/ATen/native/TensorFactoryies.cpp`，大致的调用方式是torch::zeros(...) -> at::zeros(...) -> at::native::full(...) -> at::empty(...).fill_(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "local-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[ CPUFloatType{3} ]\n",
      "y = \n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CPUIntType{3,4} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::zeros(3);\n",
    "std::cout << \"x = \" << std::endl << x << std::endl;\n",
    "\n",
    "torch::Tensor y = torch::zeros({3, 4}, torch::kInt);\n",
    "std::cout << \"y = \" << std::endl << y << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-mistake",
   "metadata": {},
   "source": [
    "## 1.3 创建值为1的tensor，使用ones(...)函数\n",
    "\n",
    "关于 ones(...) 的实现，参见 `{pytorch}/aten/src/ATen/native/TensorFactoryies.cpp`；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "functional-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[ CPUFloatType{5} ]\n",
      "<<--->>\n",
      "\n",
      "y = \n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[ CPUIntType{3,4} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::ones(5);\n",
    "printT(x);\n",
    "\n",
    "torch::Tensor y = torch::ones({3, 4}, torch::kInt);\n",
    "printT(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-labor",
   "metadata": {},
   "source": [
    "## 1.4 创建值为随机数的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rolled-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.1285  0.9279  0.7102  0.0708\n",
      " 0.1471  0.9567  0.4445  0.4089\n",
      " 0.3608  0.2170  0.0640  0.1550\n",
      "[ CPUFloatType{3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      " 0.2627  0.1366  0.4849  0.5107\n",
      " 0.9867  0.7163  0.6169  0.2492\n",
      " 0.8460  0.5982  0.3123  0.3386\n",
      "[ CPUDoubleType{3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      "(1,.,.) = \n",
      "  0.5616  1.9860 -0.7539  0.6147\n",
      "  0.3723  1.1199  0.0314 -0.3824\n",
      "  1.1765  1.1200  1.6882  0.0757\n",
      "\n",
      "(2,.,.) = \n",
      "  1.0651 -0.9554  1.3552 -0.0833\n",
      "  0.1462  0.7340 -0.9628 -0.1699\n",
      "  0.2851  1.0005 -2.5001  0.4952\n",
      "\n",
      "(3,.,.) = \n",
      "  0.3271  0.7396  1.5614 -1.1357\n",
      "  1.5070  0.4975 -0.4004 -0.6605\n",
      "  0.1210 -0.8439  0.4541  0.1603\n",
      "\n",
      "(4,.,.) = \n",
      "  0.7235 -0.1257  0.6587  0.4246\n",
      "  1.8904 -0.8455  0.3811 -0.8818\n",
      " -0.6453 -1.8369 -1.2223 -0.7683\n",
      "\n",
      "(5,.,.) = \n",
      " -1.8756  2.1590  0.0637  0.5578\n",
      " -0.7250 -0.5003  1.6985  0.3623\n",
      " -2.6475 -0.5697 -0.8971  0.0202\n",
      "[ CPUFloatType{5,3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      "a = \n",
      " 5\n",
      " 5\n",
      " 9\n",
      " 7\n",
      "[ CPUIntType{4} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::rand({3, 4});\n",
    "std::cout << x << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor y = torch::rand({3, 4}, torch::kFloat64);\n",
    "std::cout << y << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor z = torch::randn({5, 3, 4}, torch::kFloat32);\n",
    "std::cout << z << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor a = torch::randint(1/*low*/, 10/*high*/, {4}/*size*/, torch::kInt32);\n",
    "std::cout << \"a = \" << std::endl << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-comparative",
   "metadata": {},
   "source": [
    "## 1.5 根据已有tensor创建新的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imperial-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      " 6  6  6\n",
      " 6  6  6\n",
      " 6  6  6\n",
      "[ CPUFloatType{3,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t = torch::ones({3,3});\n",
    "t += 5;\n",
    "\n",
    "torch::Tensor a(t);\n",
    "std::cout << \"a = \" << std::endl << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respective-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.3738  1.7974 -1.0115\n",
      "-1.4172  1.2568  0.4390\n",
      "-0.7792 -2.4275  1.0625\n",
      " 0.2488  0.1114  0.0361\n",
      "-0.7440 -0.5427  2.0843\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor a = torch::ones({5,3});\n",
    "a = torch::randn_like(a);\n",
    "\n",
    "std::cout << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-mediterranean",
   "metadata": {},
   "source": [
    "更多例子请参考 [Tensor Creation API](https://pytorch.org/cppdocs/notes/tensor_creation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-sapphire",
   "metadata": {},
   "source": [
    "# 2. Tensor的相关操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-rates",
   "metadata": {},
   "source": [
    "## 2.1 加法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "national-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[ CPUFloatType{5,3} ]\n",
      "\n",
      "y =\n",
      "-0.4262  0.2588 -1.2324\n",
      " 1.5842 -1.4629  0.5925\n",
      "-0.2029  0.6585 -0.0634\n",
      " 2.2986 -0.6072  0.9584\n",
      " 2.4718  1.3781  1.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "\n",
      "x+y =\n",
      " 0.5738  1.2588 -0.2324\n",
      " 2.5842 -0.4629  1.5925\n",
      " 0.7971  1.6585  0.9366\n",
      " 3.2986  0.3928  1.9584\n",
      " 3.4718  2.3781  2.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n",
      "torch::add(x,y) =\n",
      " 0.5738  1.2588 -0.2324\n",
      " 2.5842 -0.4629  1.5925\n",
      " 0.7971  1.6585  0.9366\n",
      " 3.2986  0.3928  1.9584\n",
      " 3.4718  2.3781  2.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n",
      "y.add_(x) =\n",
      " 0.5738  1.2588 -0.2324\n",
      " 2.5842 -0.4629  1.5925\n",
      " 0.7971  1.6585  0.9366\n",
      " 3.2986  0.3928  1.9584\n",
      " 3.4718  2.3781  2.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::ones({5,3});\n",
    "torch::Tensor y = torch::randn({5,3});\n",
    "\n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"y =\" << std::endl;\n",
    "std::cout << (y) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"x+y =\" << std::endl;\n",
    "std::cout << (x+y) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"torch::add(x,y) =\" << std::endl;\n",
    "std::cout << torch::add(x,y) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"y.add_(x) =\" << std::endl;\n",
    "std::cout << y.add_(x) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-essence",
   "metadata": {},
   "source": [
    "## 2.2 索引\n",
    "借助于torch::Tensor::index()和torch::Tensor::index_put_()函数，我们可以在libtorch中实现类似pytorch中对tensor的切片存取操作。具体说明详见[tensor_indexing](https://pytorch.org/cppdocs/notes/tensor_indexing.html)页面."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compliant-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[None]=\n",
      " 0  1  2  3  4\n",
      "[ CPUFloatType{1,5} ]\n",
      "\n",
      "(in python) x[Ellipsis, ...]=\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[3]=\n",
      "3\n",
      "[ CPUFloatType{} ]\n",
      "\n",
      "(in python) x[True, False]=\n",
      "[ CPUFloatType{0,5} ]\n",
      "\n",
      "(in python) x[1::2]=\n",
      " 1\n",
      " 3\n",
      "[ CPUFloatType{2} ]\n",
      "\n",
      "(in python) x[::2]=\n",
      " 0\n",
      " 2\n",
      " 4\n",
      "[ CPUFloatType{3} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define SIZE (5)\n",
    "\n",
    "torch::Tensor x = torch::zeros(SIZE);\n",
    "\n",
    "for (int i = 0; i < SIZE; i++) {\n",
    "    x[i] = i;\n",
    "}\n",
    "    \n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "/* *\n",
    " *  Getter ops\n",
    " */\n",
    "std::cout << \"(in python) x[None]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::None})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[Ellipsis, ...]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Ellipsis, \"...\"})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[3]=\" << std::endl;\n",
    "std::cout << (x.index({3})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[True, False]=\" << std::endl;\n",
    "std::cout << (x.index({true,false,true,false,true,false,true,false,true,false,false,true,false,true,false})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[1::2]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Slice(1, torch::indexing::None, 2)})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[::2]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Slice(torch::indexing::None, torch::indexing::None, 2)})) << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "later-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[None] = 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[Ellipsis, ...] = 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[3] = 3\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[True, False] = 4\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[1::2] = 5\n",
      " 2\n",
      " 5\n",
      " 2\n",
      " 5\n",
      " 2\n",
      "[ CPUFloatType{5} ]\n",
      "\n",
      "(in python) x[::2] = 6\n",
      " 6\n",
      " 5\n",
      " 6\n",
      " 5\n",
      " 6\n",
      "[ CPUFloatType{5} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define SIZE (5)\n",
    "\n",
    "torch::Tensor x = torch::zeros(SIZE);\n",
    "\n",
    "for (int i = 0; i < SIZE; i++) {\n",
    "    x[i] = i;\n",
    "}\n",
    "    \n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "/* *\n",
    " *  Setter ops\n",
    " */\n",
    "std::cout << \"(in python) x[None] = 1\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::None}, 1)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[Ellipsis, ...] = 2\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::Ellipsis, \"...\"}, 2)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[3] = 3\" << std::endl;\n",
    "std::cout << (x.index_put_({3}, 3)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[True, False] = 4\" << std::endl;\n",
    "std::cout << (x.index_put_({true,false,true,false,true,false,true,false,true,false,false,true,false,true,false}, 4)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[1::2] = 5\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::Slice(1, torch::indexing::None, 2)}, 5)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[::2] = 6\" << std::endl;\n",
    "std::cout << (x.index_put_({torch::indexing::Slice(torch::indexing::None, torch::indexing::None, 2)}, 6)) << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-jaguar",
   "metadata": {},
   "source": [
    "### Python 与 C++ 索引类型对照表\n",
    "\n",
    "|Python | C++ (assuming using namespace torch::indexing) |\n",
    "|:---|:---|\n",
    "|None|None|\n",
    "|Ellipsis|Ellipsis|\n",
    "|...|\"...\"|\n",
    "|123|123|\n",
    "|True|true|\n",
    "|False|false|\n",
    "|: or ::|Slice() or Slice(None, None) or Slice(None, None, None)|\n",
    "|1: or 1::|Slice(1, None) or Slice(1, None, None)|\n",
    "|:3 or :3:|Slice(None, 3) or Slice(None, 3, None)|\n",
    "|::2|Slice(None, None, 2)|\n",
    "|1:3|Slice(1, 3)|\n",
    "|1::2|Slice(1, None, 2)|\n",
    "|:3:2|Slice(None, 3, 2)|\n",
    "|1:3:2|Slice(1, 3, 2)|\n",
    "|torch.tensor([1, 2])|torch::tensor({1, 2})|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-tuner",
   "metadata": {},
   "source": [
    "### 其它索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "material-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "  0   1   2   3\n",
      "  4   5   6   7\n",
      "  8   9  10  11\n",
      "[ CPUFloatType{3,4} ]\n",
      "\n",
      "<<< tensor.index_select >>>\n",
      " 1\n",
      " 2\n",
      "[ CPULongType{2} ]\n",
      "\n",
      "x.index_select(dim = 0, index = idx) =\n",
      "  4   5   6   7\n",
      "  8   9  10  11\n",
      "[ CPUFloatType{2,4} ]\n",
      "\n",
      "x.index_select(dim = 1, index = idx) =\n",
      "  1   2\n",
      "  5   6\n",
      "  9  10\n",
      "[ CPUFloatType{3,2} ]\n",
      "\n",
      "<<< tensor.masked_select >>>\n",
      " 0  0  0  0\n",
      " 0  0  1  1\n",
      " 1  1  1  1\n",
      "[ CPUBoolType{3,4} ]\n",
      "\n",
      "x.masked_select(mask = mask) =\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      " 10\n",
      " 11\n",
      "[ CPUFloatType{6} ]\n",
      "\n",
      "<<< tensor.nonzero >>>\n",
      "注意，返回值是非零元素下标，即x,y \n",
      "x.nonzero() =\n",
      " 0  1\n",
      " 0  2\n",
      " 0  3\n",
      " 1  0\n",
      " 1  1\n",
      " 1  2\n",
      " 1  3\n",
      " 2  0\n",
      " 2  1\n",
      " 2  2\n",
      " 2  3\n",
      "[ CPULongType{11,2} ]\n",
      "\n",
      "<<< tensor.gather >>>\n",
      "注意，index tensor必须指明类型为int64\n",
      " 4  5\n",
      " 4  5\n",
      "[ CPUFloatType{2,2} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::zeros({3,4});\n",
    "\n",
    "for (int i = 0; i < 3; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "        x[i][j] = i*4+j;\n",
    "    }\n",
    "}\n",
    "    \n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "/** Warning:\n",
    " *  a known issue: with xeus-cling, if you call torch::from_blob,\n",
    " *  there will be a link error, \n",
    " *  \n",
    " *  IncrementalExecutor::executeFunction: \n",
    " *  symbol '__emutls_v._ZSt11__once_call' unresolved \n",
    " *  while linking function '_GLOBAL__sub_I_cling_module_8'!\n",
    " *\n",
    " *\n",
    " *  so I write this example in pure \n",
    " *  c++ code in folder : 'cpp_project/basic_ops'.\n",
    " */\n",
    "// std::vector<int32_t> v = {1,2,7,8}; \n",
    "// auto idx = torch::from_blob(v.data(), v.size(), torch::kInt32);\n",
    "\n",
    "\n",
    "std::cout << \"<<< tensor.index_select >>>\" << std::endl;\n",
    "torch::Tensor idx = torch::arange(1,3);\n",
    "std::cout << (idx) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"x.index_select(dim = 0, index = idx) =\" << std::endl;\n",
    "std::cout << (x.index_select(0,idx)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"x.index_select(dim = 1, index = idx) =\" << std::endl;\n",
    "std::cout << (x.index_select(1,idx)) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "std::cout << \"<<< tensor.masked_select >>>\" << std::endl;\n",
    "torch::Tensor mask = x > 5;\n",
    "std::cout << (mask) << std::endl << std::endl;\n",
    "std::cout << \"x.masked_select(mask = mask) =\" << std::endl;\n",
    "std::cout << (x.masked_select(mask)) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"<<< tensor.nonzero >>>\" << std::endl;\n",
    "std::cout << \"注意，返回值是非零元素下标，即x,y \"<< std::endl << \"x.nonzero() =\" << std::endl;\n",
    "std::cout << (x.nonzero()) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"<<< tensor.gather >>>\" << std::endl;\n",
    "std::cout << \"注意，index tensor必须指明类型为int64\" << std::endl;\n",
    "torch::Tensor g = torch::ones({2,2}, torch::kInt64);\n",
    "std::cout << (x.gather(0, g)) << std::endl << std::endl;\n",
    "// std::cout << (torch::gather(x, 0, g, false)) << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-cannon",
   "metadata": {},
   "source": [
    "## 2.3 广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "minor-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a+b) = \n",
      " 3  3  3\n",
      " 3  3  3\n",
      " 3  3  3\n",
      "[ CPUFloatType{3,3} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor a = torch::ones({1,3});\n",
    "torch::Tensor b = torch::ones({3,1});\n",
    "\n",
    "b = b + 1;\n",
    "\n",
    "printT((a+b));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-request",
   "metadata": {},
   "source": [
    "\n",
    "## 2.4 改变形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "royal-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      "  0   1   2\n",
      "  3   4   5\n",
      "  6   7   8\n",
      "  9  10  11\n",
      " 12  13  14\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<--->>\n",
      "\n",
      "y = \n",
      "  0   1   2   3   4\n",
      "  5   6   7   8   9\n",
      " 10  11  12  13  14\n",
      "[ CPUFloatType{3,5} ]\n",
      "<<--->>\n",
      "\n",
      "x.resize_({1, w*h}) = \n",
      "  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14\n",
      "[ CPUFloatType{1,15} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "/* *\n",
    " *  Change shapes\n",
    " */\n",
    "constexpr int w = 3;\n",
    "constexpr int h = 5;\n",
    "torch::Tensor x = torch::zeros({h,w});\n",
    "\n",
    "for (int i = 0; i < h; i++) {\n",
    "    for (int j = 0; j < w; j++) {\n",
    "        x[i][j] = i*w+j;\n",
    "    }\n",
    "}\n",
    "\n",
    "printT(x);\n",
    "\n",
    "torch::Tensor y = x.view({w, -1});\n",
    "printT(y);\n",
    "\n",
    "\n",
    "/*\n",
    " * resize_(...) 参见 ATen/native/Resize.cpp\n",
    " */\n",
    "printT(x.resize_({1, w*h}));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-emperor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
