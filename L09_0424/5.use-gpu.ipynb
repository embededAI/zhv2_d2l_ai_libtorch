{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surface-citation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@0x7fe38536eb60"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../inc/macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../inc/load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../inc/custom_def.hpp\"\n",
    "/*import matplotlibcpp*/\n",
    "#include \"../inc/load_matplotlibcpp.hpp\"\n",
    "/*import opencv*/\n",
    "#include \"../inc/load_opencv.hpp\"\n",
    "\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include <cmath>\n",
    "\n",
    "\n",
    "\n",
    "std::cout << std::boolalpha;\n",
    "\n",
    "// Use (void) to silent unused warnings.\n",
    "#define assertm(exp, msg) assert(((void)msg, exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "apart-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define VAR_NAME(Variable) (#Variable)\n",
    "\n",
    "void print_tensor_size(std::string name, torch::Tensor t)\n",
    "{\n",
    "    int dims = t.dim();\n",
    "    std::cout << name << \" dims is (\";\n",
    "    for (int i = 0; i < dims; i++) {\n",
    "        std::cout << t.size(i);\n",
    "        if (i < (dims - 1)) std::cout << \" x \";\n",
    "    }\n",
    "    std::cout << \")\" << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 26 10:52:21 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.181.07   Driver Version: 418.181.07   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 29%   44C    P0    29W / 120W |   1151MiB /  6078MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2209      G   /usr/lib/xorg/Xorg                           383MiB |\n",
      "|    0      3942      G   compiz                                       203MiB |\n",
      "|    0      5773      G   ...AAgAAAAAAAAACAAAAAAAAAA= --shared-files   220MiB |\n",
      "|    0     26219      G   ...AAgAAAAAAAAACAAAAAAAAAA= --shared-files   261MiB |\n",
      "|    0     28181      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files    71MiB |\n",
      "|    0     29775      G   ...quest-channel-token=6282949599619654927     8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-crash",
   "metadata": {},
   "source": [
    "**计算设备**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dutch-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "// torch.device('cpu'), torch.cuda.device('cuda'), torch.cuda.device('cuda:1')\n",
    "\n",
    "///https://pytorch.org/cppdocs/api/structc10_1_1_device.html#_CPPv4N3c106DeviceE\n",
    "\n",
    "torch::Device device_c = torch::kCPU;\n",
    "\n",
    "torch::Device device_gpu = torch::kCUDA;\n",
    "\n",
    "device_gpu.set_index(0);\n",
    "//如果有多个gpu，还可以设置其它值，eg:\n",
    "//device_gpu.set_index(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-phase",
   "metadata": {},
   "source": [
    "**查询可用gpu的数量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applicable-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch::cuda::is_available() = \n",
      "true\n",
      "<<--->>\n",
      "\n",
      "torch::cuda::device_count() = \n",
      "1\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printT(torch::cuda::is_available());\n",
    "printT(torch::cuda::device_count());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-tracker",
   "metadata": {},
   "source": [
    "**这两个函数允许我们在请求的GPU不存在的情况下运行代码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inappropriate-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Device try_gpu(int i=0)\n",
    "{\n",
    "    std::cout << \"calling try_gpu() ...\" << std::endl;\n",
    "    if (torch::cuda::device_count() >= (i+1)) {\n",
    "        return torch::Device(torch::kCUDA, i);\n",
    "    }\n",
    "    \n",
    "    std::cout << \"no gpu found!\" << std::endl;\n",
    "    return torch::Device(\"cpu\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "popular-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "void try_all_gpus()\n",
    "{\n",
    "    std::cout << \"calling try_all_gpus() ...\" << std::endl;\n",
    "    std::vector<torch::Device> devices;\n",
    "\n",
    "    if (torch::cuda::device_count()) {\n",
    "        int c = torch::cuda::device_count();\n",
    "        std::cout << \"total gpu count is : \" << torch::cuda::device_count() << std::endl;\n",
    "        for (int i = 0; i < c; i++) {\n",
    "            devices.push_back(torch::Device(torch::kCUDA, i));\n",
    "        }\n",
    "    } else {\n",
    "        devices.push_back(torch::Device(\"cpu\"));\n",
    "    }\n",
    "    return devices;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n"
     ]
    }
   ],
   "source": [
    "try_gpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aquatic-canal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "no gpu found!\n"
     ]
    }
   ],
   "source": [
    "try_gpu(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acknowledged-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_all_gpus() ...\n",
      "total gpu count is : 1\n"
     ]
    }
   ],
   "source": [
    "try_all_gpus();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-queen",
   "metadata": {},
   "source": [
    "**查询张量所在的设备**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "seventh-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.device() = \n",
      "cpu\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto x = torch::tensor({1, 2, 3});\n",
    "printT(x.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-recipe",
   "metadata": {},
   "source": [
    "**存储在GPU上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "blocked-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "X = \n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[ CUDAFloatType{2,3} ]\n",
      "<<--->>\n",
      "\n",
      "X.device() = \n",
      "cuda:0\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto X = torch::ones({2, 3}, try_gpu());\n",
    "printT(X);\n",
    "printT(X.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-hammer",
   "metadata": {},
   "source": [
    "**第二个GPU上创建一个随机张量**\n",
    "\n",
    "注：本人机器没有第二张GPU，因此只能用cuda：0。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "signal-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "Y = \n",
      " 0.9221  0.5072  0.3604\n",
      " 0.1224  0.2166  0.6024\n",
      "[ CUDAFloatType{2,3} ]\n",
      "<<--->>\n",
      "\n",
      "Y.device() = \n",
      "cuda:0\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto Y = torch::rand({2, 3}, try_gpu(0));\n",
    "printT(Y);\n",
    "printT(Y.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-kuwait",
   "metadata": {},
   "source": [
    "**要计算X + Y，我们需要决定在哪里执行这个操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "marine-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[ CUDAFloatType{2,3} ]\n",
      "<<--->>\n",
      "\n",
      "X.device() = \n",
      "cuda:0\n",
      "<<--->>\n",
      "\n",
      "Z = \n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[ CUDAFloatType{2,3} ]\n",
      "<<--->>\n",
      "\n",
      "Z.device() = \n",
      "cuda:0\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto Z = X.to(torch::kCUDA);\n",
    "printT(X);\n",
    "printT(X.device());\n",
    "printT(Z);\n",
    "printT(Z.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-quality",
   "metadata": {},
   "source": [
    "**现在数据在同一个GPU上（Z和Y都在），我们可以将它们相加**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spoken-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y + Z = \n",
      " 1.9221  1.5072  1.3604\n",
      " 1.1224  1.2166  1.6024\n",
      "[ CUDAFloatType{2,3} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printT(Y + Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "looking-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z.to(torch::kCUDA).equal(Z) = \n",
      "true\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printT(Z.to(torch::kCUDA).equal(Z));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-victory",
   "metadata": {},
   "source": [
    "**神经网络与GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "happy-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "net->forward(X) = \n",
      "0.01 *\n",
      "-3.5769\n",
      " -3.5769\n",
      "[ CUDAFloatType{2,1} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::nn::Sequential net(torch::nn::Linear(3, 1));\n",
    "net->to(try_gpu());\n",
    "\n",
    "printT(net->forward(X));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-spyware",
   "metadata": {},
   "source": [
    "**确认模型参数存储在同一个GPU上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "according-aside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w->device() = \n",
      "cuda:0\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// net[0].weight.data.device\n",
    "auto od = net[0]->named_parameters();\n",
    "auto w = od.find(\"weight\");\n",
    "\n",
    "if(w != nullptr) {\n",
    "    printT(w->device());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-robinson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
