{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surface-citation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@0x1120a7c30"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../inc/macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../inc/load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../inc/custom_def.hpp\"\n",
    "/*import matplotlibcpp*/\n",
    "#include \"../inc/load_matplotlibcpp.hpp\"\n",
    "/*import opencv*/\n",
    "#include \"../inc/load_opencv.hpp\"\n",
    "\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include <cmath>\n",
    "\n",
    "\n",
    "\n",
    "std::cout << std::boolalpha;\n",
    "\n",
    "// Use (void) to silent unused warnings.\n",
    "#define assertm(exp, msg) assert(((void)msg, exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "apart-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define VAR_NAME(Variable) (#Variable)\n",
    "\n",
    "void print_tensor_size(std::string name, torch::Tensor t)\n",
    "{\n",
    "    int dims = t.dim();\n",
    "    std::cout << name << \" dims is (\";\n",
    "    for (int i = 0; i < dims; i++) {\n",
    "        std::cout << t.size(i);\n",
    "        if (i < (dims - 1)) std::cout << \" x \";\n",
    "    }\n",
    "    std::cout << \")\" << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-crash",
   "metadata": {},
   "source": [
    "**计算设备**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dutch-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "// torch.device('cpu'), torch.cuda.device('cuda'), torch.cuda.device('cuda:1')\n",
    "\n",
    "///https://pytorch.org/cppdocs/api/structc10_1_1_device.html#_CPPv4N3c106DeviceE\n",
    "\n",
    "torch::Device device_c = torch::kCPU;\n",
    "\n",
    "torch::Device device_gpu = torch::kCUDA;\n",
    "\n",
    "device_gpu.set_index(0);\n",
    "//如果有多个gpu，还可以设置其它值，eg:\n",
    "//device_gpu.set_index(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-phase",
   "metadata": {},
   "source": [
    "**查询可用gpu的数量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applicable-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch::cuda::is_available() = \n",
      "false\n",
      "<<--->>\n",
      "\n",
      "torch::cuda::device_count() = \n",
      "0\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printT(torch::cuda::is_available());\n",
    "printT(torch::cuda::device_count());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-tracker",
   "metadata": {},
   "source": [
    "**这两个函数允许我们在请求的GPU不存在的情况下运行代码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inappropriate-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Device try_gpu(int i=0)\n",
    "{\n",
    "    std::cout << \"calling try_gpu() ...\" << std::endl;\n",
    "    if (torch::cuda::device_count() >= (i+1)) {\n",
    "        return torch::Device(torch::kCUDA, i);\n",
    "    }\n",
    "    \n",
    "    std::cout << \"no gpu found!\" << std::endl;\n",
    "    return torch::Device(\"cpu\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "popular-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "void try_all_gpus()\n",
    "{\n",
    "    std::cout << \"calling try_all_gpus() ...\" << std::endl;\n",
    "    std::vector<torch::Device> devices;\n",
    "\n",
    "    if (torch::cuda::device_count()) {\n",
    "        int c = torch::cuda::device_count();\n",
    "        std::cout << \"total gpu count is : \" << torch::cuda::device_count() << std::endl;\n",
    "        for (int i = 0; i < c; i++) {\n",
    "            devices.push_back(torch::Device(torch::kCUDA, i));\n",
    "        }\n",
    "    } else {\n",
    "        devices.push_back(torch::Device(\"cpu\"));\n",
    "    }\n",
    "    return devices;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "no gpu found!\n"
     ]
    }
   ],
   "source": [
    "try_gpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aquatic-canal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "no gpu found!\n"
     ]
    }
   ],
   "source": [
    "try_gpu(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acknowledged-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_all_gpus() ...\n"
     ]
    }
   ],
   "source": [
    "try_all_gpus();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-queen",
   "metadata": {},
   "source": [
    "**查询张量所在的设备**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "seventh-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.device() = \n",
      "cpu\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto x = torch::tensor({1, 2, 3});\n",
    "printT(x.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-recipe",
   "metadata": {},
   "source": [
    "**存储在GPU上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "blocked-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "no gpu found!\n",
      "X = \n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[ CPUFloatType{2,3} ]\n",
      "<<--->>\n",
      "\n",
      "X.device() = \n",
      "cpu\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto X = torch::ones({2, 3}, try_gpu());\n",
    "printT(X);\n",
    "printT(X.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-hammer",
   "metadata": {},
   "source": [
    "**第二个GPU上创建一个随机张量**\n",
    "\n",
    "注：本人机器没有第二张GPU，因此设备类型是CPU。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "signal-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling try_gpu() ...\n",
      "no gpu found!\n",
      "Y = \n",
      " 0.1603  0.9222  0.9373\n",
      " 0.6822  0.8441  0.0749\n",
      "[ CPUFloatType{2,3} ]\n",
      "<<--->>\n",
      "\n",
      "Y.device() = \n",
      "cpu\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto Y = torch::rand({2, 3}, try_gpu(1));\n",
    "printT(Y);\n",
    "printT(Y.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-kuwait",
   "metadata": {},
   "source": [
    "**要计算X + Y，我们需要决定在哪里执行这个操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto Z = X.to(torch::kCUDA);\n",
    "printT(X);\n",
    "printT(X.device());\n",
    "printT(Z);\n",
    "printT(Z.device());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-quality",
   "metadata": {},
   "source": [
    "**现在数据在同一个GPU上（Z和Y都在），我们可以将它们相加**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "printT(Y + Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "printT(Z.to(torch::kCUDA).equal(Z));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-victory",
   "metadata": {},
   "source": [
    "**神经网络与GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::nn::Sequential net(torch::nn::Linear(3, 1));\n",
    "net = net.to(try_gpu());\n",
    "\n",
    "printT(net.forward(X));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-spyware",
   "metadata": {},
   "source": [
    "**确认模型参数存储在同一个GPU上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "// net[0].weight.data.device\n",
    "auto w = net[0].find(\"weight\");\n",
    "\n",
    "if(w != nullptr) {\n",
    "    printT(w->device());\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
